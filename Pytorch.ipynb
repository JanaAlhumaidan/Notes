{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x = torch.empty(size = (rows,coloums))\n",
    "x = torch.zeros((rows,coloums))\n",
    "x = torch.ones((rows,coloums))\n",
    "x = torch.rand((rows,coloums))\n",
    "x = torch.eye(rows,coloums)\n",
    "x = torch.arange(start= ,end= ,step= )\n",
    "x = torch.linspace(start= ,end= ,step= )\n",
    "x = torch.empty(size = (rows,coloums)).normal_(mean= , std= )\n",
    "x = torch.empty(size = (rows,coloums)).uniform_( , )\n",
    "x = torch.diag(torch.ones(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array to Tensor convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(\"npFileName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype\n",
    "x.device\n",
    "x.shape\n",
    "x.requires_grad\n",
    "\n",
    "# More advanced indexing\n",
    "x = torch.arange(10)\n",
    "print(x[(x < 2) | (x > 8)])  # will be [0, 1, 9]\n",
    "print(x[x.remainder(2) == 0])  # will be [0, 2, 4, 6, 8]\n",
    "\n",
    "# Useful operations for indexing\n",
    "print(torch.where(x > 5, x, x * 2))  # all values x > 5 yield x, else x*2\n",
    "x = torch.tensor([0, 0, 1, 2, 2, 3, 4]).unique()  # x = [0, 1, 2, 3, 4]\n",
    "print(x.ndimension())  # The number of dimensions, in this case 1. if x.shape is 5x5x5 ndim would be 3\n",
    "x = torch.arange(10)\n",
    "print(x.numel())  # The number of elements in x (in this case it's trivial because it's just a vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Math & Compartion operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([9, 8, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.empty(3)\n",
    "torch.add(x, y, out=z1)  # This is one way\n",
    "z2 = torch.add(x, y)  # This is another way\n",
    "z = x + y  # This is my preferred way, simple and clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subtraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x - y  # We can do similarly as the preferred way of addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Division (A bit clunky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.true_divide(x, y)  # Will do element wise division if of equal shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inplace Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(3)\n",
    "\n",
    "t.add_(x)  # Whenever we have operation followed by _ it will mutate the tensor in place\n",
    "t += x  # Also inplace: t = t + x is not inplace, bit confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exponentiation (Element wise if vector or matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.pow(2)  # z = [1, 4, 9]\n",
    "z = x**2  # z = [1, 4, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x > 0  # Returns [True, True, True]\n",
    "z = x < 0  # Returns [False, False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "\n",
    "x3 = torch.mm(x1, x2)  # Matrix multiplication of x1 and x2, out shape: 2x3\n",
    "x3 = x1.mm(x2)  # Similar as line above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrix Exponentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_exp = torch.rand(5, 5)\n",
    "print(\n",
    "    matrix_exp.matrix_power(3)\n",
    ")  # is same as matrix_exp (mm) matrix_exp (mm) matrix_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Element wise Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x * y  # z = [9, 16, 21] = [1*9, 2*8, 3*7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.dot(x, y)  # Dot product, in this case z = 1*9 + 2*8 + 3*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Batch Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "tensor1 = torch.rand((batch, n, m))\n",
    "tensor2 = torch.rand((batch, m, p))\n",
    "out_bmm = torch.bmm(tensor1, tensor2)  # Will be shape: (b x n x p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example of broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand((5, 5))\n",
    "x2 = torch.ones((1, 5))\n",
    "z = (\n",
    "    x1 - x2\n",
    ")  # Shape of z is 5x5: How? The 1x5 vector (x2) is subtracted for each row in the 5x5 (x1)\n",
    "z = (\n",
    "    x1**x2\n",
    ")  # Shape of z is 5x5: How? Broadcasting! Element wise exponentiation for every row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other useful tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of x across dim=0\n",
    "sum_x = torch.sum(x, dim=0)  # sum_x = 6\n",
    "\n",
    "# Maximum value and its index across dim=0\n",
    "values, indices = torch.max(x, dim=0)  # values = 3, indices = 2\n",
    "\n",
    "# Minimum value and its index across dim=0\n",
    "values, indices = torch.min(x, dim=0)  # values = 1, indices = 0\n",
    "\n",
    "# Absolute values of each element in x\n",
    "abs_x = torch.abs(x)  # abs_x = tensor([1, 2, 3])\n",
    "\n",
    "# Index of the maximum value in x\n",
    "z = torch.argmax(x, dim=0)  # z = 2\n",
    "\n",
    "# Index of the minimum value in x\n",
    "z = torch.argmin(x, dim=0)  # z = 0\n",
    "\n",
    "# Mean of x (requires x to be float)\n",
    "mean_x = torch.mean(x.float(), dim=0)  # mean_x = 2.0\n",
    "\n",
    "# Create another tensor y for comparison\n",
    "y = torch.tensor([3, 1, 2])\n",
    "\n",
    "# Element-wise comparison of x and y\n",
    "z = torch.eq(x, y)  # z = tensor([False, False, False])\n",
    "\n",
    "# Sort tensor y along dim=0\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)  # sorted_y = tensor([1, 2, 3]), indices = tensor([1, 2, 0])\n",
    "\n",
    "# Clamp values in x to be within the range [0, +inf) (ReLU function)\n",
    "x_clamped = torch.clamp(x, min=0)  # x_clamped = tensor([1, 2, 3])\n",
    "# To clamp within a range [min_val, max_val], use: torch.clamp(x, min=min_val, max=max_val)\n",
    "\n",
    "# Create a boolean tensor x\n",
    "x_bool = torch.tensor([1, 0, 1, 1, 1], dtype=torch.bool)  # x_bool = tensor([True, False, True, True, True])\n",
    "\n",
    "# Check if any value in x_bool is True\n",
    "z_any = torch.any(x_bool)  # z_any = True\n",
    "\n",
    "# Check if all values in x_bool are True\n",
    "z_all = torch.all(x_bool)  # z_all = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(9) # Example\n",
    "# reshape it to be 3x3\n",
    "x_3x3 = x.view(3, 3)\n",
    "x_3x3 = x.reshape(3, 3)\n",
    "\n",
    "# add two tensors dimensions togethor\n",
    "x1 = torch.rand(2, 5)\n",
    "x2 = torch.rand(2, 5)\n",
    "print(torch.cat((x1, x2), dim=0).shape)  # Shape: 4x5\n",
    "print(torch.cat((x1, x2), dim=1).shape)  # Shape 2x10\n",
    "\n",
    "# unroll x1 into one long vector with 10 elements\n",
    "z = x1.view(-1)  # And -1 will unroll everything\n",
    "\n",
    "# Another example\n",
    "batch = 64 # there are 64 data samples in this batch.\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch, -1)  # And z.shape would be 64x10\n",
    "\n",
    "# If we want to switch x axis so that instead of 64x2x5 we have 64x5x2\n",
    "# we want dimension 0 to stay, dimension 1 to become dimension 2, dimension 2 to become dimension 1\n",
    "z = x.permute(0, 2, 1)\n",
    "\n",
    "# Splits x last dimension into chunks of 2\n",
    "z = torch.chunk(x, chunks=2, dim=1)\n",
    "print(z[0].shape) # Output: torch.Size([64, 2, 3])\n",
    "print(z[1].shape) # Output: torch.Size([64, 2, 2])\n",
    "\n",
    "# We want to add an additional dimension\n",
    "x = torch.arange(10)  # Shape is [10], let's say we want to add an additional so we have 1x10\n",
    "print(x.unsqueeze(0).shape)  # adds a dimension of size 1 at index 0, resulting in a tensor of shape [1, 10]\n",
    "print(x.unsqueeze(1).shape)  # adds a dimension of size 1 at index 1, resulting in a tensor of shape [10, 1].\n",
    "\n",
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1) # 1x1x10\n",
    "\n",
    "# Perhaps unsurprisingly\n",
    "z = x.squeeze(1)  # removes a dimension at index 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
